- Date:: 2015-05-20
- Authors:: seve
- Status:: In review, Action Items in Progress
- Summary::  All CRUD functionality was inoperable on production data portal for 2.5 hrs because of database failures
- Impact:: Data portal was nonfunctional until issue was resolved, unknown # of users were unable to access 
- Root Causes:: Our RDS read and write DB instances for `corpora-prod-corpora-api` failed to start after prod promotion due to mismatched postgres engine version between aws and terraform
- **Trigger**: Prod promotion
- **Resolution**: Pinned rds `engine_version` to `10.14` rather than previous `10.11` [scinfra#376](https://github.com/chanzuckerberg/single-cell-infra/pull/376)
- **Detection**: Datadog home-page-full-load test failed, notify slack that prod was down [slack link](https://chanzuckerbergteam.slack.com/archives/CV7PFVABC/p1621557230003400)
- **Action Items**:
    - | Action Item | Type | Owner | Resolution/Ticket |
      | --- | --- | --- | --- |
       | Discuss with team-happy our longterm prevention plan | prevent | team | This is a bug owned by TF, short term fix is implemented (version pinning, and automated upgrade disabled) |
       | Move TFE alerts to seperate channel | clean-up | team + infra | Create new channel and ping happy to move (TODO) |
       | Discuss cutoff for prod deployments | prevention | team | Discuss at next retro (TODO) |
       | Announce deployments and follow through with status | prevention | team | Discuss at next retro (TODO) |
       | https://github.com/chanzuckerberg/corpora-data-portal/runs/2635424904?check_suite_focus=true should have aborted happy cli should exit with non-0 on failure | bug | happy | Notified, ticket to be written (IN PROGRESS) |


 ---
## Lessons Learned
- **What went well**
    - Our Datadog alert worked as expected notifying us of down time
    - Single cell team was able to diagnose and address the problem ourselves
    - No loss of data
- **What went wrong**
    - Late in day promotion led to us working into evening
    - No backup environment forced us to diagnose and push a fix to get functionality back up
        - ideally we would have the ability to revert the promotion while we find a fix
    - A decent amount of noise misled us during diagnosis
- **Where we got lucky**
    - Late in day downtime means little to no user impact
    - gen-epi team ran into exact same issue, slack search led to solution
## Timeline::
- 2021-05-20 **(all times PST)**
    - 5:07 Trent begin a prod deployment using happy cli ([github workflow link](https://github.com/chanzuckerberg/corpora-data-portal/runs/2635059033?check_suite_focus=true))
    - 5:08 Workflow errors failing to apply terraform changes ** ESTIMATED OUTAGE BEGINS** — RDS Container fails to start
    - 5:24 **DOWNTIME NOTFICATION** Datadog notifies about staging api being down([slack link](https://chanzuckerbergteam.slack.com/archives/CV7PFVABC/p1621556699002800))
    - 5:24 **DOWNTIME NOTFICATION** Datadog notifies about production homepage down([slack link](https://chanzuckerbergteam.slack.com/archives/CV7PFVABC/p1621557230003400))
    - 5:26 Trent attempts second prod deployment fails with same error([github workflow link](https://github.com/chanzuckerberg/corpora-data-portal/runs/2635159223?check_suite_focus=true))
    - 5:40 **INCIDENT BEGINS** Seve verifies and notifies primary(Trent) and secondary(Madison) on-call that prod is down
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2F9W3Wm-6mcS.png?alt=media&token=b6b5c5d9-46a7-405a-b127-cbce6f81b8ef)
        - [Seve shares api error](https://chanzuckerbergteam.slack.com/archives/CV7PFVABC/p1621557639004400) asks if pending terraform plans are related
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FSITp91nf6v.png?alt=media&token=4f17014a-437e-4a09-8839-d0fc0b048382)
        - [slack link](https://chanzuckerbergteam.slack.com/archives/CV7PFVABC/p1621557751005300)
    - 5:45 Seve verifies that failing host name is correct in TFE
    - 5:55 Arathi finds that a production push was just made
        - [Workflow Link](https://github.com/chanzuckerberg/corpora-data-portal/runs/2635159223?check_suite_focus=true)
    - 6:01 Seve determines that GH Action failure and prod failure timing was in sync, reaches out to team happy regarding error
        - Incorrectly focuses on script error and not TF error:
`Container did not start. Current status STOPPED: CannotPullContainerError: Error response from daemon: manifest for ***/corpora-backend:sha-4d910ba not found`
    - 6:05 Madison notices that there were back to back deployments with same error
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FEo623hMezD.png?alt=media&token=6e8932eb-ccb8-4a10-ac9b-4e992ce8addb)
        - Arathi says that the failure should imply that prod didn't upgrade/change
    - 6:06 Seve asks if the team should attempt to fix by pushing an old SHA to prod
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2Ft83r5zbSvI.png?alt=media&token=68fa684f-9921-45f4-b811-3dcd18e57235)
    - 6:09 Local deploy fails similarly, Seve incorrectly assumes the trailing error is the most relevant
    - 6:18 Madison asks if we can attempt deploy with happy-deploy, deploy begins
    - 6:18 Seve asks if we can check to see if RDS cluster is up and running, asks if TF reverts to working state if apply errors
    - 6:20 Madison states that RDS engine version is still at 10.14 so TF didn't downgrade
    - 6:25 happy-deploy fails
    - 6:32 Seve determines RDS DB is not running
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FFVfqUYp0gA.png?alt=media&token=3705d346-6376-4cee-8b81-09c55ccef87f)
![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FWIxD3ziKag.png?alt=media&token=1f9e86a5-5c10-4199-97be-33fec72eb4d3)
    - 6:34 Madison reruns an old prod deployment job, job fails in 2 minute as smoke tests cannot load collections
    - 6:36 Madison suggests running happy deployment with logging commented out as that is the failing point
    - 6:37 Arathi finds that RDS instances being down aligns with errors we're seeing
        - we start probing into why
    - 6:39 Seve attempts deploy with logs commented out, leads to same apply error without log errors
    - 6:46 Arathi sees postgres upgrade failure in TFE logs
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FpdWNw4Lyp5.png?alt=media&token=61f25323-4f2d-4413-86f5-f9ccf37fe56f)
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FHmZAjY49xT.png?alt=media&token=dc76fd69-1713-4527-bf86-e1a428b9867b)
    - 6:49 Seve looks a git history finds no recent changes to engine_version
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FMJ8tFrVQ43.png?alt=media&token=2212f7aa-66be-4129-979b-303ed1e84d4b)
    - 6:52 Madison sends RDS event logs showing instance shutdown with no matching startup
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2Fh06ywWU9qM.png?alt=media&token=5e1c7350-1aa8-43bc-a215-7766d605f4a5)
    - 6:55 We begin applying pending TFE changes hoping they fix our issue by 7:00 they all fail
    - 7:01 Seve attempts to find at what point psql version was set to 10.14
        - finds they all are set to 10.11 and asks if AWS forced an update
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FrRuIu1A2oJ.png?alt=media&token=f1463a28-dfd5-4b55-a618-9cc0f5763673)
    - 7:06 Madison asks if central-infra made a upgrade that conflicts with our pinning
    - 7:07 Seve searches slack history for 10.14 to see if central infra made an announcement finds gen-epi slack thread
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2Fcc_2gQ2CpV.png?alt=media&token=fa071baf-c799-4d6b-8f14-75df2eac532b)
        - we being parsing the thread trying to find their issue/fix
    - 7:10 Seve asks if fix is to pin to 10.14 and disable auto upgrades in aws
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FzLTMlTVBCt.png?alt=media&token=d7314e78-04de-4104-9b1b-c2d1e2f03016)

    - 7:11 Madison make PR to bump engine_version in `terraform/modules/corpora/backend/rds.tf` [scinfra#376](https://github.com/chanzuckerberg/single-cell-infra/pull/376)
    - 7:21 We also bump in `terraform/modules/corpora-dev/backend/rds.tf` [scinfra#377](https://github.com/chanzuckerberg/single-cell-infra/pull/377/files)
    - 7:26 We begin applying pending TFE changes
    - 7:31 Staging is back online
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FIFLn1vGMYD.png?alt=media&token=ebdaa2d4-ff67-4761-afd8-f5a146ab0ca7)
    - 7:32 Madison sees a db instance in prod RDS
    - 7:35 - 7:42 We wait for prod DB to populate
    - 7:42 Seve notices that `collection/:id` endpoints are failing
        - finds migration related issues
    - 7:44 Madison notes that the error is old
    - 7:47 Madison recommends redeploying prod, Seve remembers he pushed an old SHA
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2F1apHSDz45U.png?alt=media&token=40843315-a385-454f-a799-1dbeedbb28c8)
    - 7:52 **OUTAGE ENDS**, Datadog states prod has recovered

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FPg-9VaMUg3.png?alt=media&token=302cf2d7-38fd-46d9-ab02-9c44a747c2f3)
    - 8:03 **INCIDENT ENDS**, Team determines prod is stable 
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fseve-work%2FM4QS6U6xAC.png?alt=media&token=a5a44124-d7eb-46e2-855c-e5aba9462118)
